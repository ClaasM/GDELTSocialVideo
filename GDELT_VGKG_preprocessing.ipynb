{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the VGKG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claasmeiners/.virtualenvs/Thesis/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/claasmeiners/.virtualenvs/Thesis/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib\n",
    "import time\n",
    "from gzip import GzipFile\n",
    "import pandas as pd\n",
    "import os\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import pickle\n",
    "import threading\n",
    "from multiprocessing.dummy import Pool # use threads for I/O bound tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the relevant data\n",
    "\n",
    "- Download the HTML from the DocumentIdentifier and extract/save its tokens\n",
    "- Download the Images and classify them with tinyYoloV3 (for now)\n",
    "\n",
    "**Use crawler.py instead of the following cell - it uses multiprocessing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_count = 5000\n",
    "current_time = time.time()\n",
    "article_path = \"data/GDELT_VGKG/preprocessed/articles/%d/\" % current_time\n",
    "image_path = \"data/GDELT_VGKG/preprocessed/images/%d/\" % current_time\n",
    "\n",
    "print(image_path)\n",
    "print(article_path)\n",
    "\n",
    "with GzipFile('data/GDELT_VGKG/vgkg-20160427-part1.csv.gz') as gzipfile:\n",
    "    df = pd.read_csv(gzipfile, nrows=data_count)\n",
    "    \n",
    "    os.makedirs(article_path)\n",
    "    os.makedirs(image_path)\n",
    "    \n",
    "    f = FloatProgress(min=0, max=data_count)\n",
    "    display(f)\n",
    "    for index, article in df.iterrows():\n",
    "        f.value += 1\n",
    "        try:\n",
    "            doc = urllib.request.urlopen(article.DocumentIdentifier).read()\n",
    "            bs_doc = BeautifulSoup(doc)\n",
    "\n",
    "            # remove some tags that aren't rendered, including their content\n",
    "            # From https://www.w3schools.com/tags/ref_byfunc.asp\n",
    "            programming_tags = ['script', 'noscript', 'applet', 'embed', 'object', 'param']\n",
    "            meta_tags = ['head', 'meta', 'base', 'basefont']\n",
    "            other_tags = ['data', 'style']\n",
    "            [x.extract() for x in bs_doc.findAll(programming_tags + meta_tags + other_tags)]\n",
    "\n",
    "            # Keep only the remaining text (removing all tags etc.)\n",
    "            text = bs_doc.get_text() #re.sub('<[^<]+?>', '', str(doc))[:100]\n",
    "\n",
    "            # Tokenize the text\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "\n",
    "            # Keep only tokens that are words and more than a letter\n",
    "            alpha_tokens = [token for token in tokens if token.isalpha() and len(token) > 1]\n",
    "\n",
    "            # Keep only tokens that are either all caps or no caps or start with a capital letter\n",
    "            pattern = re.compile(\"(^[A-Z]?[a-z]+$)|(^[A-Z]+$)\")\n",
    "            word_tokens = [token for token in alpha_tokens if pattern.match(token)]\n",
    "\n",
    "\n",
    "            # Done preprocessing. Save tokens\n",
    "            file = open(\"%s/%s\" % (article_path, article.DATE), \"wb+\")\n",
    "            pickle.dump(word_tokens, file) # Date is unique(?) TODO find out\n",
    "            \n",
    "            # Download the corresponding image \n",
    "            # (for the whole dataset, we'll have to classify and then discard, unless I get proper storage)\n",
    "            urllib.request.urlretrieve(article.ImageURL, \"%s/%s\" % (image_path, article.DATE))\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e, article.DocumentIdentifier)\n",
    "            \n",
    "            \n",
    "            # TODO create number of URLS (including splitting by error type) \n",
    "            # and Number of average Characters at each stage plots\n",
    "            # TODO look into the errors in more detail (especially 403's etc.)\n",
    "            # TODO store and publicise raw html/preprocessed/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/lib\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5ec7f351cf487bb65b170d3a890041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=41.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{b'person': 5}\n",
      "{}\n",
      "{b'person': 3, b'tie': 1}\n",
      "{b'person': 1}\n",
      "{b'person': 1}\n",
      "{}\n",
      "{b'person': 1}\n",
      "{b'person': 2}\n",
      "{b'person': 2}\n",
      "{b'person': 3, b'chair': 1}\n",
      "{b'person': 3}\n",
      "{b'person': 2}\n",
      "{}\n",
      "{b'person': 1}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{b'person': 1}\n",
      "{b'person': 4}\n",
      "{}\n",
      "{b'person': 1}\n",
      "{}\n",
      "{}\n",
      "{b'car': 3}\n",
      "{b'person': 2}\n",
      "{b'person': 1}\n",
      "{b'person': 2}\n",
      "{b'person': 1, b'bicycle': 1}\n",
      "{}\n",
      "{b'person': 3}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{b'person': 1}\n",
      "{b'person': 1}\n",
      "{b'tie': 1}\n",
      "{}\n",
      "{b'person': 2}\n",
      "{b'person': 1}\n",
      "CPU times: user 4.44 s, sys: 450 ms, total: 4.89 s\n",
      "Wall time: 5.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset_time = 1535141748 # set this to which version of the collected data is to be used\n",
    "image_path = \"data/GDELT_VGKG/preprocessed/images/%d/\" % dataset_time\n",
    "image_classification_path = \"data/GDELT_VGKG/preprocessed/image_classifications/yoloV3-tiny/%d/%d/\" % (dataset_time, time.time())\n",
    "# TODO make the testing of different classifiers DRY\n",
    "\n",
    "os.makedirs(image_classification_path)\n",
    "\n",
    "sys.path += [os.getcwd()]\n",
    "os.environ['DYLD_LIBRARY_PATH'] = \"/usr/local/cuda/lib\"\n",
    "%run darknet_wrapper.py\n",
    "\n",
    "MODEL=\"yolov3-tiny\"\n",
    "net, meta = initialize_classifier(config=\"cfg/%s.cfg\"%MODEL, weights=\"weights/%s.weights\"%MODEL, data=\"cfg/coco.data\")\n",
    "\n",
    "images = os.listdir(image_path)\n",
    "f = FloatProgress(min=0, max=len(images))\n",
    "display(f)\n",
    "for image in images:\n",
    "    f.value += 1\n",
    "    try:\n",
    "        image_dir = image_path + \"/\" + image\n",
    "        result = detect(net, meta, image_dir)\n",
    "        labels = dict()\n",
    "        for label, probability, coordinates in result:\n",
    "            if label in labels: \n",
    "                labels[label]+=1 \n",
    "            else:\n",
    "                labels[label] = 1\n",
    "        # Save classification result\n",
    "        file = open(\"%s/%s\" % (image_classification_path, image), \"wb+\")\n",
    "        pickle.dump(labels, file)\n",
    "        \n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "            # Some of the files are not actually images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Classifier and the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path += [os.getcwd() + \"/Mask_RCNN\", os.getcwd(), os.getcwd() + \"/Mask_RCNN/samples/coco/\"]\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "import coco\n",
    "\n",
    "MODEL_DIR=\"Mask_RCNN/logs\"\n",
    "COCO_MODEL_PATH=\"Mask_RCNN/mask_rcnn_coco.h5\"\n",
    "\n",
    "DETECTION_THRESHOLD = .5 # .5 is the default threshold of YOLO so we're using that here as well\n",
    "\n",
    "dataset_time = 1535141748 # set this to which version of the collected data is to be used\n",
    "image_path = \"data/GDELT_VGKG/preprocessed/images/%d/\" % dataset_time\n",
    "image_classification_path = \"data/GDELT_VGKG/preprocessed/image_classifications/maskrcnn/%d/%d/\" % (dataset_time, time.time())\n",
    "# TODO make the testing of different classifiers DRY\n",
    "\n",
    "os.makedirs(image_classification_path)\n",
    "\n",
    "image_names = os.listdir(image_path)[:10]\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = len(images)\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiying the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 images\n",
      "image                    shape: (346, 607, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (324, 576, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (360, 420, 3)         min:   85.00000  max:  255.00000  uint8\n",
      "image                    shape: (551, 600, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (699, 306, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (400, 581, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (337, 598, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (409, 600, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (720, 1200, 3)        min:    0.00000  max:  255.00000  uint8\n",
      "image                    shape: (466, 965, 3)         min:    0.00000  max:  255.00000  uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claasmeiners/.virtualenvs/Thesis/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molded_images            shape: (10, 1024, 1024, 3)   min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (10, 93)              min:    0.00000  max: 1200.00000  float64\n",
      "anchors                  shape: (10, 261888, 4)       min:   -0.35390  max:    1.29134  float32\n",
      "CPU times: user 14min 41s, sys: 32.8 s, total: 15min 13s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import skimage\n",
    "\n",
    "try:\n",
    "    images = [skimage.io.imread(image_path + \"/\" + image) for image in image_names]\n",
    "    results = model.detect(images, verbose=1)\n",
    "except Exception as e:\n",
    "        print(e)\n",
    "        # Some of the files are not actually images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160213120000: {'person': 2, 'bicycle': 1}\n",
      "20160215040000: {'person': 7, 'tie': 1, 'potted plant': 1}\n",
      "20160215200000: {'person': 2}\n",
      "20160218080000: {'person': 8, 'tie': 3}\n",
      "20160219200000: {'person': 1, 'car': 1, 'handbag': 1}\n",
      "20160220234500: {'tie': 1, 'person': 18}\n",
      "20160222080000: {'clock': 1}\n",
      "20160223040000: {'person': 1}\n",
      "20160223200000: {'person': 1}\n",
      "20160229120000: {'person': 5}\n"
     ]
    }
   ],
   "source": [
    "# Bring the results into the same format \n",
    "index = 0\n",
    "for result in results:\n",
    "    labels = dict()\n",
    "    for class_id, score in zip(result['class_ids'],result['scores']):\n",
    "        if score > DETECTION_THRESHOLD:\n",
    "            label = class_names[int(class_id)]\n",
    "            if label in labels: \n",
    "                labels[label]+=1 \n",
    "            else:\n",
    "                labels[label] = 1\n",
    "    print(image_names[index] + \": \" + str(labels))\n",
    "    # Save classification result\n",
    "    file = open(\"%s/%s\" % (image_classification_path, image), \"wb+\")\n",
    "    pickle.dump(labels, file)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
